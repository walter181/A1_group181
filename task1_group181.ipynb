{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCbAmQ47iqK4"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "# FIT5196 Task 1 in Assessment 1\n",
    "#### Student Name: xxxx\n",
    "#### Student ID: xxxx\n",
    "\n",
    "Date: xxxx\n",
    "\n",
    "\n",
    "Environment: Python xxxx\n",
    "\n",
    "Libraries used:\n",
    "* re (for regular expression, installed and imported) \n",
    "* pandas (for data manipulation) \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjBFqYK4iqK5"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "## Table of Contents\n",
    "\n",
    "</div>    \n",
    "\n",
    "[1. Introduction](#Intro) <br>\n",
    "[2. Importing Libraries](#libs) <br>\n",
    "[3. Examining Patent Files](#examine) <br>\n",
    "[4. Loading and Parsing Files](#load) <br>\n",
    "$\\;\\;\\;\\;$[4.1. Defining Regular Expressions](#Reg_Exp) <br>\n",
    "$\\;\\;\\;\\;$[4.2. Reading Files](#Read) <br>\n",
    "$\\;\\;\\;\\;$[4.3. Whatever else](#latin) <br>\n",
    "[5. Writing to CSV/JSON File](#write) <br>\n",
    "$\\;\\;\\;\\;$[5.1. Verification - using the sample files](#test_xml) <br>\n",
    "[6. Summary](#summary) <br>\n",
    "[7. References](#Ref) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcbqK3KliqK6"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEFdSCIUiqK6"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 1.  Introduction  <a class=\"anchor\" name=\"Intro\"></a>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGg4-8VSiqK6"
   },
   "source": [
    "This assessment regards extracting data from semi-sctuctured text files. The dataset contained 500 `.txt` files which included various information about user reviews. In particular, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6Ql-W6BiqK7"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnctlBF6iqK7"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "## 2.  Importing Libraries  <a class=\"anchor\" name=\"libs\"></a>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQOLlwmAiqK7"
   },
   "source": [
    "The packages to be used in this assessment are imported in the following. They are used to fulfill the following tasks:\n",
    "\n",
    "* **re:** to define and use regular expressions\n",
    "* **pandas:** ...\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mKGO6FAXiqK7"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMWqFiW4jewp"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DEWD9qIiqK8"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "Z814ttFYiqK8"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 3.  Examining Raw Data <a class=\"anchor\" name=\"examine\"></a>\n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YVIqb_miqK8"
   },
   "source": [
    "First of all, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp3TG3fyiqK9"
   },
   "source": [
    "Having examined the file content, the following observations were made:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBEASWLfiqK-"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "iDoVeDSHiqK-"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "\n",
    "## 4.  Loading and Parsing Files <a class=\"anchor\" name=\"load\"></a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z24HaN8hiqK-"
   },
   "source": [
    "In this section, the files are parsed and processed. First of all, appropriate regular expressions are defined to extract desired information when reading the files. ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQ0tuwvZiqK-"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rApp_Ic9iqK-"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "### 4.1. Defining Regular Expressions <a class=\"anchor\" name=\"Reg_Exp\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knauV0VViqK-"
   },
   "source": [
    "Defining correct regular expressions is crucial in extracting desired information from the text efficiently. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# the file path\n",
    "text_path = './student_group181'\n",
    "\n",
    "all_text_data = \"\"\n",
    "\n",
    "# 文件名列表\n",
    "file_names = [\n",
    "    'group181_0.txt', 'group181_1.txt', 'group181_2.txt', 'group181_3.txt', \n",
    "    'group181_4.txt', 'group181_5.txt', 'group181_6.txt', 'group181_7.txt', \n",
    "    'group181_8.txt', 'group181_9.txt', 'group181_10.txt', 'group181_11.txt',\n",
    "    'group181_12.txt', 'group181_13.txt', 'group181_14.txt'\n",
    "]\n",
    "\n",
    "# 逐个读取每个文件\n",
    "for file_name in file_names:\n",
    "    file_path = f\"{text_path}/{file_name}\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        all_text_data += content  # 将内容拼接起来\n",
    "        \n",
    "split_txt = '?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n",
    "final_split= '</dataset><record>|<dataset><record>'\n",
    "\n",
    "#通过split_txt，把内容切分成不同文件的部分\n",
    "folder_text = all_text_data.split(split_txt)\n",
    "# #删除第一个的空数值\n",
    "if folder_text[0] == \"\":\n",
    "    folder_text.pop(0)\n",
    "\n",
    "#建立一个list，使用for循环便利folder_text，按照每个用户进行分割储存\n",
    "final_split_text = []\n",
    "for text in folder_text:\n",
    "    slipted_info = re.split(final_split,text)\n",
    "    final_split_text.extend(slipted_info)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_expression = r\"<[^>]*?ser[^>]*?>\\s*(\\d{21})\\s*<[^>]*?/[^>]*?ser[^>]*?>\"\n",
    "# time_expression = r\"((?:<.{1,3}ime>\\s*)|(?:<.{0,2}[Dd]ate>\\s*))(.*?)((?:<.{1,3}ime>)|(?:<.{0,2}[Dd]ate>))\"\n",
    "\n",
    "time_expression = r\"(?:<.{1,3}ime\\s*/?>\\s*|<.{0,2}[Dd]ate\\s*/?>\\s*)(\\d+)(?:\\s*<\\s*/\\s*.{1,3}ime\\s*/?>|<\\s*/\\s*.{0,2}[Dd]ate\\s*/?>)\"\n",
    "\n",
    "#这里我没有修改(就加入了一个大小写，需要再次修改)\n",
    "rate_expression = r\"(?:<.{0,2}[Rr]ate>\\s*)(\\d+)(?:<.{0,2}[Rr]ate>)\"\n",
    "rateing_expression = r\"(?:<.{0,2}[Rr]ating>\\s*)(\\d+)(?:<.{0,2}[Rr]ating>)\"\n",
    "\n",
    "text_expression = r\"(?:<.{0,3}[Tt]ext>\\s*)(.*?)(?:<.{0,3}[Tt]ext>)\"\n",
    "review_expression = r\"(?:<.{0,2}[Rr]eview>\\s*)(.*?)(?:<.{0,2}[Rr]eview>)\"\n",
    "name_expression = r\"(?:<.{0,7}[Nn]ame>\\s*)(.*?)(?:<.{0,7}[Nn]ame\\s*>)\"\n",
    "# #改了一些，可以在修改\n",
    "response_expression = r\"(?:<.{0,3}[Rr]esp.{0,4}>\\s*)(.*?)(?:<.{0,3}[Rr]esp.{0,4}>)\"\n",
    "picture_expression = r\"(?:<.{0,2}[Pp]ic.{1,5}>\\s*)(.*?)(?:<.{0,2}[Pp]ic.{1,5}>)\"\n",
    "\n",
    "gmap_id_expression=r\"(?:<.{0,2}[Gg]map.{1,3}>\\s*)(.*?)(?:<.{0,2}[Gg]map.{1,3}>)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4716"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试0.txt数据\n",
    "try_date = folder_text[0]\n",
    "text_date = []\n",
    "test_user_id_pattern = re.compile(r\"<[^>]*?ser[^>]*?>\\s*(\\d{21})\\s*<[^>]*?/[^>]*?ser[^>]*?>\", re.DOTALL)\n",
    "test_user_id_matches = test_user_id_pattern.findall(try_date)\n",
    "text_date.extend(test_user_id_matches)\n",
    "len(text_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44697\n"
     ]
    }
   ],
   "source": [
    "rate_pattern = re.compile(rate_expression, re.DOTALL)\n",
    "rateing_pattern = re.compile(rateing_expression, re.DOTALL)\n",
    "rate_list = []\n",
    "for i in final_split_text:\n",
    "    time = rate_pattern.findall(i)\n",
    "    if not time:\n",
    "        time = rateing_pattern.findall(i)\n",
    "    \n",
    "    rate_list.extend(time)\n",
    "    \n",
    "print(len(rate_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44697\n"
     ]
    }
   ],
   "source": [
    "user_id_list = []\n",
    "gmap_id_list = []\n",
    "time_list = []\n",
    "date_list = []\n",
    "rate_list = []\n",
    "review_list = []\n",
    "response_list = []\n",
    "picture_list = []\n",
    "name_list = []\n",
    "\n",
    "user_id_pattern = re.compile(user_id_expression, re.DOTALL)\n",
    "gmap_id_pattern = re.compile(gmap_id_expression, re.DOTALL)\n",
    "time_pattern = re.compile(time_expression, re.DOTALL)\n",
    "\n",
    "rate_pattern = re.compile(rate_expression, re.DOTALL)\n",
    "rateing_pattern = re.compile(rateing_expression, re.DOTALL)\n",
    "\n",
    "text_pattern = re.compile(text_expression, re.DOTALL)\n",
    "review_pattern = re.compile(review_expression, re.DOTALL)\n",
    "\n",
    "response_pattern = re.compile(response_expression, re.DOTALL)\n",
    "picture_pattern = re.compile(picture_expression, re.DOTALL)\n",
    "name_pattern = re.compile(name_expression,re.DOTALL)\n",
    "\n",
    "\n",
    "#处理现在总的list数据，通过正则表达式提取需要的数据\n",
    "for text in final_split_text:\n",
    "     \n",
    "     user_id_matches = user_id_pattern.findall(text)\n",
    "     user_id_list.extend(user_id_matches)\n",
    "     \n",
    "     gmap_id_matches = gmap_id_pattern.findall(text)\n",
    "     gmap_id_list.extend(gmap_id_matches)\n",
    "     \n",
    "     time_matches = time_pattern.findall(text)\n",
    "     time_list.extend(time_matches)\n",
    "     \n",
    "     rate_matches = rate_pattern.findall(text)\n",
    "     if not rate_matches:\n",
    "        rate_matches = rateing_pattern.findall(text)\n",
    "     rate_list.extend(rate_matches)\n",
    "     \n",
    "     review_matches = review_pattern.findall(text)\n",
    "     if not review_matches:\n",
    "        review_matches = text_pattern.findall(text)\n",
    "     review_list.extend(review_matches)\n",
    "     \n",
    "     response_matches = response_pattern.findall(text)\n",
    "     response_list.extend(response_matches)\n",
    "     \n",
    "     picture_matches = picture_pattern.findall(text)\n",
    "     picture_list.extend(picture_matches)\n",
    "     \n",
    "     \n",
    "     name_matches = name_pattern.findall(text)\n",
    "     name_list.extend(name_matches)\n",
    "\n",
    "print(len(name_list))\n",
    "print(name_list[0])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<time>',\n",
       " '<//time>',\n",
       " '< /time>',\n",
       " '< time>',\n",
       " '<//Time>',\n",
       " '< Time>',\n",
       " '<Time>',\n",
       " '</Time>',\n",
       " '</time>',\n",
       " '< /Time>']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_pattern = re.compile(\"<.{1,10}>\")\n",
    "attributes = attributes_pattern.findall(all_text_data)\n",
    "\n",
    "list_values = list(set(attributes))\n",
    "\n",
    "date_attributes = []\n",
    "for attr in list_values:\n",
    "  if 'date' in attr.lower():\n",
    "    date_attributes.append(attr)\n",
    "\n",
    "# date_attributes\n",
    "\n",
    "\n",
    "time_attributes = []\n",
    "for attr in list_values:\n",
    "  if 'time' in attr.lower():\n",
    "    time_attributes.append(attr)\n",
    "\n",
    "time_attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTqmBHIKiqK_"
   },
   "source": [
    "These patterns are used in the next step when reading the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZ-njkJciqK_"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGcAMvmhiqK_"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "### 4.2. Reading Files <a class=\"anchor\" name=\"Read\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llC5D5M3iqK_"
   },
   "source": [
    "In this step, all files are read and parsed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-brytUfiqLA"
   },
   "source": [
    "Let's take a look at the first ten elements of the lists generated. We can see that ids, reviews,etc. are parsed and stored correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MD-LSS76iqLA"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtwS6ttqiqLA"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "### 4.3. Whatever else <a class=\"anchor\" name=\"latin\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IJ63oV9iqLA"
   },
   "source": [
    "the rest of your methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7g9k9Fb8iqLB"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "KVwmp1LfiqLE"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "\n",
    "## 5.  Writing to JSON File <a class=\"anchor\" name=\"write\"></a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFHcHFPGiqLE"
   },
   "source": [
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0WT10TJiqLE"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "3XcaJBATiqLE"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "### 5.1. Verification of the Generated JSON File <a class=\"anchor\" name=\"test_xml\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO8vwKqkiqLF"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "\n",
    "## 6. Summary <a class=\"anchor\" name=\"summary\"></a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEg_xQdXiqLF"
   },
   "source": [
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20RDw_JDiqLF"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QdX7ozQiqLF"
   },
   "source": [
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnASfTmniqLF"
   },
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li7bchX9iqLF"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "\n",
    "## 7. References <a class=\"anchor\" name=\"Ref\"></a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkWuWC3NiqLF"
   },
   "source": [
    "\n",
    "\n",
    "[1]<a class=\"anchor\" name=\"ref-2\"></a> Why do I need to add DOTALL to python regular expression to match new line in raw string, https://stackoverflow.com/questions/22610247, Accessed 30/08/2022.\n",
    "\n",
    "....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVyuz4LciqLG"
   },
   "source": [
    "## --------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "task1_xxxxxxx.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
